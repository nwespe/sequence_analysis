#!/usr/bin/env python
# -*- coding: utf-8 -*-
# compile_report.py

""" Description
    This script will generate a single report on alignment statistics for bam files
    using data collected by picard tools CollectAlignmentSummaryMetrics.
    User input will be a directory where the data files are present
    and a csv file describing samples to be analyzed.
"""

__author__= "Nichole Wespe"

import subprocess
import os
import sys
import csv
import re
import fnmatch
import argparse

script_directory = os.path.dirname(sys.argv[0])

parser = argparse.ArgumentParser(description = "Specify a directory where input files are present and a csv file describing samples to be analyzed.")
parser.add_argument('-d', '--directory', required=True, help='Full path of directory containing text files generated by map_report.py. Files can be in subdirectories of this directory.')
parser.add_argument('-f', '--csv_file', required=True, help='Full path to csv file containing names of samples.')
args = parser.parse_args()

directory = args.directory
csv_file = args.csv_file

def input_eval():
    
    """ Determine if inputs are a directory and a readable csv file
    """
    try:
        os.path.isdir(directory)
    except:
        print directory + " is not a directory"
        sys.exit(1)
##TODO    try:
##        csv_open = open(csv_file, 'rU')
##        csv_reader = csv.reader(csv_open)
##        #some other function here to check file?
##    except:
##        print csv_file + " is not readable csv file."
##        return 1
        
    print "Now working on files in " + directory


def read_csv_file():
    
    """ Read csv file of sample names
    """
# problem: can't read csv file with uneven numbers of entries in rows
# hack: format all empty cells as text in excel before saving as csv
    
    csv_open = open(csv_file, 'rU')
    csv_reader = csv.reader(csv_open)
    row1 = next(csv_reader)

    # make set of sample names to pass to other functions
    individual_samples = set() # set of samples to analyze bam files
    for row in csv_reader:
        for sample in row: 
            if sample: individual_samples.add(sample)

    print "Received directions to compile data metrics for " + str(len(individual_samples)) + " unique samples"

    return individual_samples


def find_map_report_files(samples):

    # find files
    data_files = []
    for r, d, f in os.walk(directory):
        for item in f:
            if fnmatch.fnmatch(item, '*asm.txt'):
                data_files.append(os.path.abspath(os.path.join(r, item)))
    print "Found " + str(len(data_files)) + " map report files"

    # match files to samples
    matched_samples = []
    for sample in samples:
        sample_data = fnmatch.filter(data_files, '*'+sample+'*')
        if len(sample_data) > 1: print "Warning: more than one data file found for " + sample
        elif len(sample_data) == 0: print "Missing data file for " + sample
        else: matched_samples.append((sample, sample_data[0]))

    print "Matched " + str(len(matched_samples)) + " samples to map report files"
    return matched_samples


def parse_data_files(matched_samples):

    # get data from files
    sample_info = {}
    for sample, file in matched_samples:
        with open(file, 'rU') as report:
            lines = report.readlines()
            data = lines[9].split('\t') # data I want are on line 10 of text file
            total_reads = data[1]
            pf_reads_aligned = data[5]
            pct_pf_reads_aligned = data[6]
            pf_aligned_bases = data[7]
            pf_hq_aligned_q20_bases = data[10]
            mean_read_length = data[15]
            total_bases = float(total_reads) * float(mean_read_length)
            x_coverage = total_bases / 12157105
            pct_pf_aligned_bases = float(pf_aligned_bases) / total_bases
            pct_pf_hq_aligned_q20_bases = float(pf_hq_aligned_q20_bases) / total_bases
            aligned_coverage = float(pf_hq_aligned_q20_bases) / 12157105
            entries = [total_reads, pf_reads_aligned, pct_pf_reads_aligned, mean_read_length, total_bases, x_coverage, pf_aligned_bases, pct_pf_aligned_bases, pf_hq_aligned_q20_bases, pct_pf_hq_aligned_q20_bases, aligned_coverage]
            sample_info[sample] = '\t'.join(str(x) for x in entries)

    # write output file
    analysis_name = os.path.splitext(os.path.basename(csv_file))[0]
    output = os.path.abspath(os.path.join(directory, analysis_name + '_alignment_data.txt'))
    print output
    outputfile = open(output, 'w')
    outputfile.write('sample \t total_reads \t aligned_reads \t percent_reads_aligned \t mean_read_length \t total_bases \t total_coverage \t aligned_bases \t percent_bases_aligned \t hq_aligned_bases \t percent_hq_aligned_bases \t aligned_coverage\n')
    for sample, data in sample_info.iteritems():
        outputfile.write(sample + '\t' + data + '\n')

 # reader = csv.reader (report, delimiter='\t') # read tab-delimited file 
           

def main(): # run analyses of bam files using functions defined above

    """ check input,
        extract sample names from csv file
        find map report files
        get relevant info and write to file
    """
    # initialize lists
    individual_samples = set() 

    input_eval() # check input

    individual_samples = read_csv_file()

    matched_samples = find_map_report_files(individual_samples)

    parse_data_files(matched_samples)

    print "Compilation of reports completed."

    sys.exit(0)


if __name__ == "__main__": 
    main()

